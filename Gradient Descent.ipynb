{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbfe703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b9c098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>CTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.4</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.5</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.9</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.7</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CGPA   CTC\n",
       "0   8.3  4.35\n",
       "1   9.4  5.40\n",
       "2   7.5  3.50\n",
       "3   8.9  3.75\n",
       "4   9.7  4.50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'CGPA':[8.3,9.4,7.5,8.9,9.7,6.4],\n",
    "     'CTC':[4.35,5.40,3.50,3.75,4.5,3.5]}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2cd6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,[0]]\n",
    "y = df.iloc[:,-1]\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0dd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.3]\n",
      " [9.4]\n",
      " [7.5]\n",
      " [8.9]\n",
      " [9.7]\n",
      " [6.4]]\n",
      "[4.35 5.4  3.5  3.75 4.5  3.5 ]\n"
     ]
    }
   ],
   "source": [
    "X = X.values\n",
    "y = y.values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939544f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "049dde77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83.],\n",
       "       [94.],\n",
       "       [75.],\n",
       "       [89.],\n",
       "       [97.],\n",
       "       [64.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 10\n",
    "res = np.dot(m,X)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeeebfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "m is 0.7710987506236078 and b is 0.9730867538102282\n",
      "y_pred [[7.37320638 8.22141501 6.75632738 7.83586563 8.45274463 5.90811876]]\n",
      "Cost 10.970225267926153\n",
      "loss_m 55.38471886934264 loss_b 6.515892601388828\n",
      "Iteration 3 ends here\n",
      "--------------------------------------\n",
      "m is 0.7157140317542652 and b is 0.9665708612088394\n",
      "y_pred [[6.90699732 7.69428276 6.3344261  7.33642574 7.90899697 5.54714066]]\n",
      "Cost 8.085072477536242\n",
      "loss_m 47.37856381862941 loss_b 5.576089853772382\n",
      "Iteration 4 ends here\n",
      "--------------------------------------\n",
      "m is 0.6683354679356358 and b is 0.9609947713550671\n",
      "y_pred [[6.50817916 7.24334817 5.97351078 6.90918044 7.44384881 5.23834177]]\n",
      "Cost 5.973737377645963\n",
      "loss_m 40.52970576205732 loss_b 4.772136372833107\n",
      "Iteration 5 ends here\n",
      "--------------------------------------\n",
      "m is 0.6278057621735785 and b is 0.9562226349822339\n",
      "y_pred [[6.16701046 6.8575968  5.66476585 6.54369392 7.04593853 4.97417951]]\n",
      "Cost 4.42867676170603\n",
      "loss_m 34.67085636782603 loss_b 4.084395023669016\n",
      "Iteration 6 ends here\n",
      "--------------------------------------\n",
      "m is 0.5931349058057525 and b is 0.952138239958565\n",
      "y_pred [[5.87515796 6.52760635 5.40065003 6.2310389  6.70554683 4.74820164]]\n",
      "Cost 3.2980119331860163\n",
      "loss_m 29.658908984462872 loss_b 3.4960672370667205\n",
      "Iteration 7 ends here\n",
      "--------------------------------------\n",
      "m is 0.5634759968212896 and b is 0.9486421727214982\n",
      "y_pred [[5.62549295 6.24531654 5.17471215 5.96357854 6.41435934 4.55488855]]\n",
      "Cost 2.4705991025911778\n",
      "loss_m 25.371443156964677 loss_b 2.9927826922525753\n",
      "Iteration 8 ends here\n",
      "--------------------------------------\n",
      "m is 0.5381045536643249 and b is 0.9456493900292456\n",
      "y_pred [[5.41191719 6.00383219 4.98143354 5.73477992 6.16526356 4.38951853]]\n",
      "Cost 1.8651040062923796\n",
      "loss_m 21.703734418306574 loss_b 2.5622483113748604\n",
      "Iteration 9 ends here\n",
      "--------------------------------------\n",
      "m is 0.5164008192460183 and b is 0.9430871417178708\n",
      "y_pred [[5.22921394 5.79725484 4.81609329 5.53905443 5.95217509 4.24805238]]\n",
      "Cost 1.4220067874432347\n",
      "loss_m 18.566196318304634 loss_b 2.193947992152448\n",
      "Iteration 10 ends here\n",
      "--------------------------------------\n",
      "m is 0.4978346229277137 and b is 0.9408931937257183\n",
      "y_pred [[5.07292056 5.62053865 4.67465287 5.37162134 5.76988904 4.12703478]]\n",
      "Cost 1.097751222615344\n",
      "loss_m 15.882192209529958 loss_b 1.8788857444418459\n",
      "Iteration 11 ends here\n",
      "--------------------------------------\n",
      "m is 0.4819524307181837 and b is 0.9390143079812765\n",
      "y_pred [[4.93921948 5.46936716 4.55365754 5.22839094 5.61395289 4.02350986]]\n",
      "Cost 0.8604631659376792\n",
      "loss_m 13.58616334155678 loss_b 1.6093659566468272\n",
      "Iteration 12 ends here\n",
      "--------------------------------------\n",
      "m is 0.46836626737662695 and b is 0.9374049420246297\n",
      "y_pred [[4.82484496 5.34004786 4.45015195 5.10586472 5.48055774 3.93494905]]\n",
      "Cost 0.6868173358536862\n",
      "loss_m 11.622027540887451 loss_b 1.3788054248181503\n",
      "Iteration 13 ends here\n",
      "--------------------------------------\n",
      "m is 0.45674423983573953 and b is 0.9360261365998115\n",
      "y_pred [[4.72700333 5.22942199 4.36160794 5.00104987 5.36644526 3.85918927]]\n",
      "Cost 0.5597444511379478\n",
      "loss_m 9.941809363148824 loss_b 1.1815725531176644\n",
      "Iteration 14 ends here\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# lr = learning_rate\n",
    "# epochs = no of iterations\n",
    "cost_val = []\n",
    "def grad_desc(X,y,lr,epochs):\n",
    "    m, b = 1, 1\n",
    "    for i in range(epochs):\n",
    "        print(f'm is {m} and b is {b}')\n",
    "        y_pred = np.dot(m, X.T) + b  # y_pred = mX + b \n",
    "        cost = np.mean(np.square(y - y_pred))\n",
    "        loss_m = -(2/len(X)) * np.sum((y-y_pred)*X.T)\n",
    "        loss_b = -(2/len(X)) * np.sum((y-y_pred))\n",
    "        m = m - lr*loss_m\n",
    "        b = b - lr*loss_b\n",
    "        cost_val.append(cost)\n",
    "        print('y_pred',y_pred)\n",
    "        print('Cost',cost)\n",
    "        print('loss_m',loss_m,'loss_b',loss_b)\n",
    "        print(f'Iteration {i} ends here')\n",
    "        print('--------------------------------------')\n",
    "        \n",
    "grad_desc(X,y,lr=0.001,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a604f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7945ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.662500000000005, 20.300364924341924, 14.912804862988812, 10.970225267926153, 8.085072477536242, 5.973737377645963, 4.42867676170603, 3.2980119331860163, 2.4705991025911778, 1.8651040062923796, 1.4220067874432347, 1.097751222615344, 0.8604631659376792, 0.6868173358536862, 0.5597444511379478]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cost or Error')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(cost_val)\n",
    "plt.plot(range(15),cost_val,marker='o',color='maroon')\n",
    "plt.xlabel('No of iterations')\n",
    "plt.ylabel('Cost or Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_iter2 = [7.91819382, 8.83762054, 7.24951984, 8.41969931, 9.08837329, 6.33009311]\n",
    "y_true = [4.35, 5.4,  3.5,  3.75, 4.5,  3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "148a9e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad Desc for no of iterations = 1\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 2\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 3\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 4\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "m is 0.7710987506236078 and b is 0.9730867538102282\n",
      "y_pred [[7.37320638 8.22141501 6.75632738 7.83586563 8.45274463 5.90811876]]\n",
      "Cost 10.970225267926153\n",
      "loss_m 55.38471886934264 loss_b 6.515892601388828\n",
      "Iteration 3 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 5\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "m is 0.7710987506236078 and b is 0.9730867538102282\n",
      "y_pred [[7.37320638 8.22141501 6.75632738 7.83586563 8.45274463 5.90811876]]\n",
      "Cost 10.970225267926153\n",
      "loss_m 55.38471886934264 loss_b 6.515892601388828\n",
      "Iteration 3 ends here\n",
      "--------------------------------------\n",
      "m is 0.7157140317542652 and b is 0.9665708612088394\n",
      "y_pred [[6.90699732 7.69428276 6.3344261  7.33642574 7.90899697 5.54714066]]\n",
      "Cost 8.085072477536242\n",
      "loss_m 47.37856381862941 loss_b 5.576089853772382\n",
      "Iteration 4 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 6\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "m is 0.7710987506236078 and b is 0.9730867538102282\n",
      "y_pred [[7.37320638 8.22141501 6.75632738 7.83586563 8.45274463 5.90811876]]\n",
      "Cost 10.970225267926153\n",
      "loss_m 55.38471886934264 loss_b 6.515892601388828\n",
      "Iteration 3 ends here\n",
      "--------------------------------------\n",
      "m is 0.7157140317542652 and b is 0.9665708612088394\n",
      "y_pred [[6.90699732 7.69428276 6.3344261  7.33642574 7.90899697 5.54714066]]\n",
      "Cost 8.085072477536242\n",
      "loss_m 47.37856381862941 loss_b 5.576089853772382\n",
      "Iteration 4 ends here\n",
      "--------------------------------------\n",
      "m is 0.6683354679356358 and b is 0.9609947713550671\n",
      "y_pred [[6.50817916 7.24334817 5.97351078 6.90918044 7.44384881 5.23834177]]\n",
      "Cost 5.973737377645963\n",
      "loss_m 40.52970576205732 loss_b 4.772136372833107\n",
      "Iteration 5 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 7\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "m is 0.7710987506236078 and b is 0.9730867538102282\n",
      "y_pred [[7.37320638 8.22141501 6.75632738 7.83586563 8.45274463 5.90811876]]\n",
      "Cost 10.970225267926153\n",
      "loss_m 55.38471886934264 loss_b 6.515892601388828\n",
      "Iteration 3 ends here\n",
      "--------------------------------------\n",
      "m is 0.7157140317542652 and b is 0.9665708612088394\n",
      "y_pred [[6.90699732 7.69428276 6.3344261  7.33642574 7.90899697 5.54714066]]\n",
      "Cost 8.085072477536242\n",
      "loss_m 47.37856381862941 loss_b 5.576089853772382\n",
      "Iteration 4 ends here\n",
      "--------------------------------------\n",
      "m is 0.6683354679356358 and b is 0.9609947713550671\n",
      "y_pred [[6.50817916 7.24334817 5.97351078 6.90918044 7.44384881 5.23834177]]\n",
      "Cost 5.973737377645963\n",
      "loss_m 40.52970576205732 loss_b 4.772136372833107\n",
      "Iteration 5 ends here\n",
      "--------------------------------------\n",
      "m is 0.6278057621735785 and b is 0.9562226349822339\n",
      "y_pred [[6.16701046 6.8575968  5.66476585 6.54369392 7.04593853 4.97417951]]\n",
      "Cost 4.42867676170603\n",
      "loss_m 34.67085636782603 loss_b 4.084395023669016\n",
      "Iteration 6 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 8\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "m is 0.7710987506236078 and b is 0.9730867538102282\n",
      "y_pred [[7.37320638 8.22141501 6.75632738 7.83586563 8.45274463 5.90811876]]\n",
      "Cost 10.970225267926153\n",
      "loss_m 55.38471886934264 loss_b 6.515892601388828\n",
      "Iteration 3 ends here\n",
      "--------------------------------------\n",
      "m is 0.7157140317542652 and b is 0.9665708612088394\n",
      "y_pred [[6.90699732 7.69428276 6.3344261  7.33642574 7.90899697 5.54714066]]\n",
      "Cost 8.085072477536242\n",
      "loss_m 47.37856381862941 loss_b 5.576089853772382\n",
      "Iteration 4 ends here\n",
      "--------------------------------------\n",
      "m is 0.6683354679356358 and b is 0.9609947713550671\n",
      "y_pred [[6.50817916 7.24334817 5.97351078 6.90918044 7.44384881 5.23834177]]\n",
      "Cost 5.973737377645963\n",
      "loss_m 40.52970576205732 loss_b 4.772136372833107\n",
      "Iteration 5 ends here\n",
      "--------------------------------------\n",
      "m is 0.6278057621735785 and b is 0.9562226349822339\n",
      "y_pred [[6.16701046 6.8575968  5.66476585 6.54369392 7.04593853 4.97417951]]\n",
      "Cost 4.42867676170603\n",
      "loss_m 34.67085636782603 loss_b 4.084395023669016\n",
      "Iteration 6 ends here\n",
      "--------------------------------------\n",
      "m is 0.5931349058057525 and b is 0.952138239958565\n",
      "y_pred [[5.87515796 6.52760635 5.40065003 6.2310389  6.70554683 4.74820164]]\n",
      "Cost 3.2980119331860163\n",
      "loss_m 29.658908984462872 loss_b 3.4960672370667205\n",
      "Iteration 7 ends here\n",
      "--------------------------------------\n",
      "Grad Desc for no of iterations = 9\n",
      "m is 1 and b is 1\n",
      "y_pred [[ 9.3 10.4  8.5  9.9 10.7  7.4]]\n",
      "Cost 27.662500000000005\n",
      "loss_m 88.47333333333333 loss_b 10.4\n",
      "Iteration 0 ends here\n",
      "--------------------------------------\n",
      "m is 0.9115266666666667 and b is 0.9896\n",
      "y_pred [[8.55527133 9.55795067 7.82605    9.10218733 9.83140867 6.82337067]]\n",
      "Cost 20.300364924341924\n",
      "loss_m 75.68418897777778 loss_b 8.898746222222224\n",
      "Iteration 1 ends here\n",
      "--------------------------------------\n",
      "m is 0.835842477688889 and b is 0.9807012537777778\n",
      "y_pred [[7.91819382 8.83762054 7.24951984 8.41969931 9.08837329 6.33009311]]\n",
      "Cost 14.912804862988812\n",
      "loss_m 64.74372706528119 loss_b 7.614499967549631\n",
      "Iteration 2 ends here\n",
      "--------------------------------------\n",
      "m is 0.7710987506236078 and b is 0.9730867538102282\n",
      "y_pred [[7.37320638 8.22141501 6.75632738 7.83586563 8.45274463 5.90811876]]\n",
      "Cost 10.970225267926153\n",
      "loss_m 55.38471886934264 loss_b 6.515892601388828\n",
      "Iteration 3 ends here\n",
      "--------------------------------------\n",
      "m is 0.7157140317542652 and b is 0.9665708612088394\n",
      "y_pred [[6.90699732 7.69428276 6.3344261  7.33642574 7.90899697 5.54714066]]\n",
      "Cost 8.085072477536242\n",
      "loss_m 47.37856381862941 loss_b 5.576089853772382\n",
      "Iteration 4 ends here\n",
      "--------------------------------------\n",
      "m is 0.6683354679356358 and b is 0.9609947713550671\n",
      "y_pred [[6.50817916 7.24334817 5.97351078 6.90918044 7.44384881 5.23834177]]\n",
      "Cost 5.973737377645963\n",
      "loss_m 40.52970576205732 loss_b 4.772136372833107\n",
      "Iteration 5 ends here\n",
      "--------------------------------------\n",
      "m is 0.6278057621735785 and b is 0.9562226349822339\n",
      "y_pred [[6.16701046 6.8575968  5.66476585 6.54369392 7.04593853 4.97417951]]\n",
      "Cost 4.42867676170603\n",
      "loss_m 34.67085636782603 loss_b 4.084395023669016\n",
      "Iteration 6 ends here\n",
      "--------------------------------------\n",
      "m is 0.5931349058057525 and b is 0.952138239958565\n",
      "y_pred [[5.87515796 6.52760635 5.40065003 6.2310389  6.70554683 4.74820164]]\n",
      "Cost 3.2980119331860163\n",
      "loss_m 29.658908984462872 loss_b 3.4960672370667205\n",
      "Iteration 7 ends here\n",
      "--------------------------------------\n",
      "m is 0.5634759968212896 and b is 0.9486421727214982\n",
      "y_pred [[5.62549295 6.24531654 5.17471215 5.96357854 6.41435934 4.55488855]]\n",
      "Cost 2.4705991025911778\n",
      "loss_m 25.371443156964677 loss_b 2.9927826922525753\n",
      "Iteration 8 ends here\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(f'Grad Desc for no of iterations = {i}')\n",
    "    grad_desc(X,y,lr=0.001,epochs=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8a2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f474cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab48d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cf0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798909d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
